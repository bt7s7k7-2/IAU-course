{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Statistical Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.stats as sm_stats\n",
    "import statsmodels.stats.api as sms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 1. Data samples: two groups, each group has 10 students\n",
    "- Those who went to lectures (attended at least 50% of the lectures)\n",
    "- Those who did not attend lectures (others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "sample_size = 10\n",
    "m1 = 80\n",
    "m2 = 78\n",
    "s = 5\n",
    "\n",
    "attended = stats.norm(loc=m1, scale=s)\n",
    "not_attended = stats.norm(loc=m2, scale=s)\n",
    "\n",
    "# rvs: Random Varieties\n",
    "a_sample = attended.rvs(size=sample_size)\n",
    "na_sample = not_attended.rvs(size=sample_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1.2 What does our data look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "a_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "na_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "a_sample.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "na_sample.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Students who *didn't* go to lectures have a higher final grade on average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Theoretically, we should observe a difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# pdf: Probability Density Function\n",
    "x = np.linspace(60, 100, 100)\n",
    "plt.plot(x, attended.pdf(x), 'b')\n",
    "plt.plot(x, not_attended.pdf(x), 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### So can I declare that not going to lectures improves the final grade in the subject?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'attended': np.repeat([True, False], 10), 'score': np.concatenate((a_sample, na_sample))})\n",
    "sns.boxplot(x=df['attended'], y=df['score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### The basic problem is that we are not measuring whole populations, but only their samples\n",
    "\n",
    "So we only work with estimates. **How ‚Äã‚Äãcan we be sure of them?**\n",
    "\n",
    "<img src=\"https://s3-eu-west-1.amazonaws.com/blog.omniconvert.com-media/blog/wp-content/uploads/2019/10/21150245/sample-size-definition.png \" width=\"50%\" />\n",
    "\n",
    "#### Statistics offers us tools to find out if there are differences in two statistical sets\n",
    "- Is there any difference at all? There will probably be some\n",
    "- Is the difference small or large? Statistics will not help us much here\n",
    "- Does the measured difference have any practical value? Statistics do not give us an answer to this either\n",
    "- **Is the measured difference real or just due to chance? Statistics can help us here!**\n",
    "\n",
    "## 1.3 So how to verify that the difference between the groups is real and not given by chance?\n",
    "- Statistical hypotheses testing\n",
    "- When testing hypotheses, we consider the probability that we could have achieved the given result if the experimental procedure had no effect\n",
    "- Assumption of null effect (difference) = **null hypothesis** = $H_0$\n",
    "\n",
    "**$H_0$ = The average final grade of students who attended lectures is the same as those who did not attend lectures.**\n",
    "\n",
    "- Alternative hypothesis $H_1$ (if the null $H_0$ would not apply)\n",
    "\n",
    "**$H_1$ = The average final grade of students who attended lectures is different/greater/smaller than those who did not attend lectures.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Error of the first kind (Type I) and error of the second kind (Type II)**\n",
    "\n",
    "<img src=\"https://chemicalstatistician.files.wordpress.com/2014/05/pregnant.jpg\" width=\"35%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 1.3.1 Basic steps of hypothesis testing\n",
    "1. Determine the null hypothesis $H_0$ and alternate hypothesis $H_1$\n",
    "2. Set a significance level ùõº \n",
    "3. Compute p-value using suitable test statistic ùëá  \n",
    "4. Make a decision based on p-value and ùõº \n",
    "\n",
    "**We just need to choose a suitable statistical test!**\n",
    "\n",
    "<!-- <img src=\"https://i.stack.imgur.com/idDTA.png\" /> //-->\n",
    "[<img src=\"img/critical-p-values.png\" />](https://www.geo.fu-berlin.de/en/v/soga/Basics-of-statistics/Hypothesis-Tests/Introduction-to-Hypothesis-Testing/Critical-Value-and-the-p-Value-Approach/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 1.3.2 Significance tests: Student's t-test\n",
    "\n",
    "- the t-statistic was introduced in 1908 by William Sealy Gosset while he was working as a chemist at the Guinness brewery.\n",
    "- t-test is based on **t-distribution**.\n",
    "- the t-distribution is similar to the normal distribution, but has more mass in the tails. As the number of observations increases, it approaches a normal distribution.\n",
    "- the t-test for two paired samples compares whether the difference of pairs of observations is different from zero.\n",
    " \n",
    "Calculation of t-statistics (for two independent samples):\n",
    "\n",
    "$t = \\frac{\\overline{X_1} - \\overline{X_2}}{s_p \\sqrt{\\frac{1}{n_1} - \\frac{1}{n_2}}}$ \n",
    "\n",
    "$s_p = \\sqrt{\\frac{(n_1 - 1) s^2_{X_1} + (n_2 - 1) s^2_{X_2}}{n_1 + n_2 - 2}}$\n",
    "\n",
    "Assumptions of the t-test\n",
    "- The input values are from a normal distribution\n",
    "- values come from distributions with similarly large variance (dispersion of values) - there is a t-test correction for distributions with different variance (*Welch's t-test*).\n",
    "- *t-test is resistant to slight deviations from these assumptions.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats.ttest_ind(a_sample, na_sample)\n",
    "stat, p = stats.ttest_ind(a_sample, na_sample)\n",
    "print('Ttest_indResult: statistic=', stat, 'pvalue=', p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Same distributions (fail to reject H0)')\n",
    "else:\n",
    "    print('Different distributions (reject H0)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*t-test*: $H_0$ = the means of two populations are equal\n",
    "\n",
    "- Assumption of null effect = **null hypothesis** = $H_0$\n",
    "\n",
    "in the domain: **$H_0$ = The average final grade of students who attended lectures is the same as those who did not attend lectures.**\n",
    "\n",
    "*We cannot reject $H_0$ (fail to reject $H_0$) based on the result of a *t-test* with two samples (there are 10 students in each)*\n",
    "\n",
    "**We continue with the tests!!!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 1.3.3 Normality assumption testing\n",
    "\n",
    "1. Visual inspection using a histogram or so-called quantile-quantile graph (QQ graph) - especially for large samples\n",
    "2. Normality test, e.g. using the **Shapiro-Wilk** test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# sns.distplot(a_sample, bins=5)\n",
    "sns.histplot(a_sample, bins=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# sns.distplot(na_sample, bins=5)\n",
    "sns.histplot(na_sample, bins=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 1.3.4.1 QQ plot\n",
    "\n",
    "A quantile-quantile plot (*QQ-plot*) is a visual method used to determine whether two data sets come from the same distribution. Most commonly, it compares the distribution of a sample with a theoretical normal distribution. Each point on the plot represents the quantile value in the first and second data sets being compared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "_ = sm.ProbPlot(a_sample, fit=True).qqplot(line='45')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "_ = sm.ProbPlot(na_sample, fit=True).qqplot(line='45')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**How ‚Äã‚Äãto interpret a QQ plot?**\n",
    "\n",
    "<img src=\"https://i.stack.imgur.com/ZXRkL.png\" />\n",
    "\n",
    "Source: https://stats.stackexchange.com/questions/101274/how-to-interpret-a-qq-plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 1.3.5 Shapiro-Wilk normality test\n",
    "\n",
    "- The Shapiro-Wilk test tests the null hypothesis that the data come from a normal distribution.\n",
    "- If $p < 0.05$, we reject the null hypothesis and the data probably come from a non-normal distribution. If $p > 0.05$, we do not reject the null hypothesis, that is, based on the data, we cannot declare that the data come from a different than normal distribution.\n",
    "- `scipy.stats.shapiro`: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.shapiro.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "stats.shapiro(a_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "stats.shapiro(na_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 1.3.4 Variance test: Levene Test\n",
    "\n",
    "- Levene's test tests the null hypothesis that all input samples come from distributions with equal variances.\n",
    "- If we do not reject the null hypothesis ($p > 0.05$), it means that, based on the data, we cannot claim that the samples come from distributions with different variances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**However, we did not prove that the averages are the same.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**How ‚Äã‚Äãis that possible?**\n",
    "\n",
    "We generated data from distributions with different means."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Type II error** - we used an underpowered test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1.4 Statistical power = $1 - \\beta$\n",
    "\n",
    "- The probability of finding a significant difference if one exists (rejecting $H_0$ when it is false).\n",
    "- With low test power, we cannot identify smaller effects (differences).\n",
    "- We can increase the power by increasing the number of participants (observations)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**The power of the test, or the required number of participants/observations, can be calculated in advance!**\n",
    "\n",
    "- To do this, we need to estimate the *effect size*.\n",
    "- There are several ways, such as **Cohen's d**.\n",
    "\n",
    "$d = \\frac{\\overline{x_1} - \\overline{x_2}}{s}$\n",
    "\n",
    "where\n",
    "\n",
    "$s = \\sqrt{\\frac{(n_1 - 1) s^2_{X_1} + (n_2 - 1) s^2_{X_2}}{n_1 + n_2 - 2}}$\n",
    "\n",
    "- small effect = 0.2, medium effect = 0.5, large effect = 0.8\n",
    "\n",
    "**In our example there is a difference, but we were not able to measure it: We only had 10 observations !!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def cohen_d(x1, x2):\n",
    "    nx1 = len(x1)\n",
    "    nx2 = len(x2)\n",
    "    s = np.sqrt(((nx1-1) * np.std(x1, ddof=1)**2 + (nx2-1) * np.std(x2, ddof=1)**2) / (nx1 + nx2 - 2))\n",
    "    return (np.abs(np.mean(x1) - np.mean(x2))) / s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "c_d = cohen_d(a_sample, na_sample)\n",
    "c_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sm_stats.power.tt_ind_solve_power(c_d, len(a_sample), 0.05, None, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`statsmodels.stats.power.tt_ind_solve_power`:\n",
    "https://www.statsmodels.org/stable/generated/statsmodels.stats.power.tt_ind_solve_power.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1.5 Effect size: Large effect (0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sm_stats.power.tt_ind_solve_power(c_d, None, 0.05, 0.8, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In fact, we would need fewer observations (since we generated the data, we know the true values ‚Äã‚Äãof the means and standard deviations):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sm_stats.power.tt_ind_solve_power((m1-m2)/s, None, 0.05, 0.8, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 2. Bigger data samples of 100 students for each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "a_sample2 = attended.rvs(100)\n",
    "na_sample2 = not_attended.rvs(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "a_sample2.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "na_sample2.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (10,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame({'attended': np.repeat([True, False], 100), 'score': np.concatenate((a_sample2, na_sample2))})\n",
    "sns.boxplot(x=df['attended'], y=df['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "stats.ttest_ind(a_sample2, na_sample2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- **Based on the t-test, we reject the null hypothesis**\n",
    "- But the average estimates still do not correspond to the actual values.\n",
    "- *How to find out the accuracy of this estimate, or what is the true value of the mean?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2.2 Confidence interval\n",
    "\n",
    "The confidence level $C$ (e.g., 95%) tells us the percentage of confidence intervals that would contain the true estimated population value (e.g., the mean) if we were to test infinitely many samples from the population.\n",
    "\n",
    "When the population's standard deviation is unknown, we use values from the t-distribution:\n",
    "\n",
    "$ \\overline{x} \\pm t_{\\alpha}(n-1)\\frac{s}{\\sqrt{n}} $\n",
    "\n",
    "$ \\alpha = \\frac{1-C}{2} $\n",
    "\n",
    "**Example: public opinion poll**\n",
    "\n",
    "<img src=\"img/election-poll2.png\" alt=\"Confidence intervals in an election poll\" width=\"20%\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "sms.DescrStatsW(a_sample).tconfint_mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sms.DescrStatsW(na_sample).tconfint_mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (6,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sns.barplot(x='attended', y='score', data=df, capsize=0.1, errwidth=2, palette=sns.color_palette(\"Blues\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "sms.DescrStatsW(a_sample2).tconfint_mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sms.DescrStatsW(na_sample2).tconfint_mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sns.barplot(x='attended', y='score', data=df2, capsize=0.1, errwidth=2, palette=sns.color_palette(\"Blues\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2.3 We had two groups‚Äîwhat if we had more?\n",
    "\n",
    "$\\alpha = 0.05$\n",
    "\n",
    "* 1 test: 5% probability of error\n",
    "* 2 tests: $1 ‚Äì (1-0.05)^2 \\approx 9.75\\%$ probability of error\n",
    "* 10 tests: $1 ‚Äì (1-0.05)^{10} \\approx 40.1\\%$ probability of error\n",
    "* 25 tests: $1 ‚Äì (1-0.05)^{25} \\approx 72.3\\%$ probability of error\n",
    "\n",
    "As the number of tested groups increases, the Type I error rate also increases.\n",
    "\n",
    "#### We can control Type I errors\n",
    "\n",
    "- **FWER (Familywise Error Rate)** = The probability of rejecting at least one true $H_i$ (*making a Type I error*) when testing a group of null hypotheses.\n",
    "- **Bonferroni correction**\n",
    "\n",
    "$p_i \\leq \\alpha/m$, where $m$ is the number of hypotheses (pairwise tests).\n",
    "\n",
    "For 4 test conditions, $\\alpha = 0.05$ leads to 6 pairwise tests, so $p_i \\leq 0.05/6 = 0.0083$.\n",
    "\n",
    "*Or even better‚Äîuse a test for multiple groups (e.g., ANOVA) combined with pairwise post-hoc tests.*\n",
    "\n",
    "#### Reporting the p-value is not enough\n",
    "- It only indicates whether there is any effect\n",
    "- It depends on the sample size; with sufficiently large samples, you will almost always find a significant difference\n",
    "- You should also report the **effect size**. http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3444174\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. BIGGER data samples: 100 000 students for each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "attended2 = stats.norm(80, 5)\n",
    "not_attended2 = stats.norm(79.9, 5)\n",
    "\n",
    "a_sample3 = attended2.rvs(100000)\n",
    "na_sample3 = not_attended2.rvs(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "a_sample3.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "na_sample3.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# stats.ttest_ind(a_sample3, na_sample3)\n",
    "stat, p = stats.ttest_ind(a_sample3, na_sample3)\n",
    "print('Ttest_indResult: statistic=', stat, 'pvalue=', p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Same distributions (fail to reject H0)')\n",
    "else:\n",
    "    print('Different distributions (reject H0)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in the domain: **$H_0$ = The average final grade of students who attended lectures is the same as those who did not attend lectures.**\n",
    "\n",
    "**We reject $H_0$ (Reject $H_0$) based on the result of the t-test with larger two samples !!!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *t-test* one more time\n",
    "\n",
    "- $H_0$ = the means of two populations are equal\n",
    "- Fail to Reject $H_0$: No difference between the sample means\n",
    "- Reject $H_0$: Some difference between the sample means\n",
    "\n",
    "## Finally, statistical hypothesis testing WORKS correctly !!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# You can already use statistics to test hypotheses :)\n",
    "\n",
    "**Online courses**\n",
    "\n",
    "- Statistical Inference (https://www.coursera.org/learn/statistical-inference; part of the *Data Science* specialization)\n",
    "- Statistics with Python Specialization (https://www.coursera.org/specializations/statistics-with-python)\n",
    "- Introduction to Statistics as Covered in the Social, Behavioral, and Natural Sciences (https://www.udemy.com/course/introduction-to-statistics/)\n",
    "- Statistics for Business Analytics and Data Science A-Z (https://www.udemy.com/course/data-statistics/)\n",
    "- Statistics (Khan Academy): https://www.youtube.com/playlist?list=PL1328115D3D8A2566\n",
    "\n",
    "**References**\n",
    "- Brian Caffo: Little Inference Book (https://leanpub.com/LittleInferenceBook)\n",
    "- Alex Reinhard: Statistics Done Woefully Wrong (https://www.statisticsdonewrong.com/)\n",
    "- Will Kurt: Bayesian Statistics the Fun Way (https://nostarch.com/learnbayes)\n",
    "- https://github.com/FIIT-IAU\n",
    "\n",
    "<!--\n",
    "Next step: Bayesian inference\n",
    "- Bayesian inference is a method of statistical inference in which Bayes' theorem is used to update the probability for a hypothesis as more evidence or information becomes available.\n",
    "//-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
