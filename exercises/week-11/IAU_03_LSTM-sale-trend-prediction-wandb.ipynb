{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f346237a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#    http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n",
    "# implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80adcb4f",
   "metadata": {},
   "source": [
    "# Musiker e-shop: e-commerce trend prediction\n",
    "\n",
    "### Author: Martin Sch√∂n (2024)\n",
    "\n",
    "**Raw dataset under non-disclosure agreement (NDA) with https://www.muziker.sk/**\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522d0586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e2ba72-9bf1-4a4b-bca1-2d8bec27bc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.get_logger().setLevel('FATAL')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Input, LSTM, RepeatVector\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "%matplotlib inline\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(context='paper', style='whitegrid', color_codes=True)   \n",
    "sns.set_palette(sns.color_palette([\"#017b92\", \"#f97306\", \"#ff0000\"]))  # [\"green\", \"orange\", \"red\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a764b30e",
   "metadata": {},
   "source": [
    "### Anonymized data for sale trend prediction made from NDA raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d855e3cd-7aa8-4e40-ac7f-a99f2393738d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pd.read_csv(\"data/musiker-orders_days.csv\",index_col=False, header=0)\n",
    "daily_sales = ds.orders_amount\n",
    "daily_sales.index = ds.order_created_at\n",
    "daily_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa23ca92-8096-40c4-b097-c5d390694907",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 6))\n",
    "daily_sales.plot(label='Daily Sales')\n",
    "plt.title('Daily sales')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of sales')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b56a12f-a0f8-49bd-9b86-6e9602236b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all targets y from a TimeseriesGenerator instance.\n",
    "def get_y_from_generator(gen):\n",
    "    y = None\n",
    "    for i in range(len(gen)):\n",
    "        batch_y = gen[i][1]\n",
    "        if y is None:\n",
    "            y = batch_y\n",
    "        else:\n",
    "            y = np.append(y, batch_y)\n",
    "    y = y.reshape((-1,1))\n",
    "    print(y.shape)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c435eee-6858-4b89-9c27-fd6d34339bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = daily_sales.values\n",
    "x = np.arange(0, y.size, 1)\n",
    "\n",
    "data = y.reshape(-1,1)\n",
    "print(data.shape)\n",
    "plt.rcParams[\"figure.figsize\"] = (20,4)\n",
    "plt.plot(data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9805e9e-f626-422b-b1c5-8da8b2b11885",
   "metadata": {},
   "source": [
    "# Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf65bb82-33dd-45d1-8edd-5c4bf0433b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "dftest = adfuller(data, autolag = 'AIC')\n",
    "print(\"\\t1. ADF : \",dftest[0])\n",
    "print(\"\\t2. P-Value : \", dftest[1])\n",
    "print(\"\\t3. Num Of Lags : \", dftest[2])\n",
    "          \n",
    "result = STL(data, period=6, robust = True).fit()\n",
    "plt.rcParams[\"figure.figsize\"] = (12,8)\n",
    "result.plot()\n",
    "plt.show()\n",
    "\n",
    "# data_cleaned = result.trend \n",
    "# data_cleaned = result.trend + result.seasonal \n",
    "data_cleaned = result.trend + result.seasonal + result.resid     # all data without cleaning\n",
    "\n",
    "data_cleaned = data_cleaned.flatten().reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa28e44-d98f-4d5e-948c-a3a9f1f7e251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all columns in 'data_cleaned'\n",
    "plt.figure(figsize=(24, 6))\n",
    "plt.plot(y)\n",
    "plt.plot(data_cleaned)\n",
    "plt.title('Plot of Numpy ndarray')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Values')\n",
    "plt.legend(['Actual data', 'Data cleaned'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b22d4c-cc21-4380-aec4-d07f825b2ac2",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17ecb06-a7ed-4768-b4ca-0fa1d23f8f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wandb\n",
    "import logging\n",
    "# Create logging \n",
    "logging.basicConfig(filename=\"training_log.log\",\n",
    "                    filemode='a',\n",
    "                    format='%(asctime)s,%(msecs)d %(name)s %(levelname)s %(message)s',\n",
    "                    datefmt='%H:%M:%S',\n",
    "                    level=logging.INFO)\n",
    "\n",
    "os.environ[\"WANDB_SILENT\"] = \"true\"   # silence WANDB init as it gets a bit annoying with bigger trainings\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d120a4",
   "metadata": {},
   "source": [
    "### Hyper-parameter tuning with wandb (Weights & Biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e847b9-a4f9-4eea-82df-66bc73a60567",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "class WandbCallback(Callback):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        wandb.log(logs, step=epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d20f368-d03c-4c4e-b638-a855408f4f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_tune(config: dict):\n",
    "    run_name = f\"train-lr{config['lr']}-ep{config['epochs']}-bs{config['batch_size']}-lu{config['lstm_units']}-lb{config['lookback']}-oa{config['output_activation']}\"\n",
    "    wandb.init(\n",
    "            project=\"dp_lstm\",\n",
    "            config=config,\n",
    "            name=run_name\n",
    "        )\n",
    "    \n",
    "    \n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    data_trans = scaler.fit_transform(data_cleaned)\n",
    "\n",
    "    train_size = int(len(data_trans) * 0.80)\n",
    "    test_size = len(data_trans) - train_size\n",
    "    train, test = data_trans[0:train_size,:], data_trans[train_size:len(data_trans),:]\n",
    "\n",
    "    look_back = config[\"lookback\"]\n",
    "    train_data_gen = TimeseriesGenerator(train, \n",
    "                                         train,\n",
    "                                         length=look_back, \n",
    "                                         sampling_rate=1,\n",
    "                                         stride=1,\n",
    "                                         batch_size=config[\"batch_size\"]\n",
    "                                        )\n",
    "    test_data_gen = TimeseriesGenerator(test, \n",
    "                                        test,\n",
    "                                        length=look_back, \n",
    "                                        sampling_rate=1,\n",
    "                                        stride=1,\n",
    "                                        batch_size=config[\"batch_size\"]\n",
    "                                       )\n",
    "\n",
    "    # model\n",
    "    x = Input(shape=(look_back, 1))\n",
    "    h = LSTM(units=config[\"lstm_units\"])(x)   \n",
    "    y = Dense(units=1, activation=config[\"output_activation\"])(h)\n",
    "    model = Model(inputs=x, outputs=y)\n",
    "    #print(model.summary())\n",
    "    \n",
    "    # compile model\n",
    "    opt = Adam(learning_rate=config['lr'])\n",
    "    model.compile(loss='mean_squared_error', optimizer=opt, metrics=['mse', 'mae'])\n",
    "    \n",
    "    wandb_callback = WandbCallback(config)\n",
    "    model.fit(train_data_gen, epochs=config[\"epochs\"], shuffle=True, callbacks=[wandb_callback])\n",
    "    \n",
    "    return model.evaluate(test_data_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60393860-8f17-4019-bb6d-cfbb0e1df771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WANDB HYPERPARAMETER TUNE, change the next line to True to use it \n",
    "wandb_tuning = False\n",
    "\n",
    "config = {\"lr\": [0.1, 0.01, 0.001],\n",
    "          \"epochs\": [5, 10, 20, 30, 50],\n",
    "          \"batch_size\": [1, 3, 5, 8],\n",
    "          \"lstm_units\": [3, 5, 7, 10],\n",
    "          \"lookback\": [7, 10, 14],\n",
    "          \"output_activation\": ['linear', 'sigmoid']\n",
    "         }\n",
    "\n",
    "if wandb_tuning:\n",
    "    %%capture --no-stdout\n",
    "    test_config = {}\n",
    "    \n",
    "    for lr in config[\"lr\"]:\n",
    "        test_config[\"lr\"] = lr\n",
    "        for epch in config[\"epochs\"]:\n",
    "            test_config[\"epochs\"] = epch\n",
    "            for bs in config[\"batch_size\"]:\n",
    "                test_config[\"batch_size\"] = bs\n",
    "                for lstm_u in config[\"lstm_units\"]:\n",
    "                    test_config[\"lstm_units\"] = lstm_u\n",
    "                    for lckb in config[\"lookback\"]:\n",
    "                        test_config[\"lookback\"] = lckb\n",
    "                        for outa in config[\"output_activation\"]:\n",
    "                            test_config[\"output_activation\"] = outa\n",
    "\n",
    "                            logging.info(f\"Training - {test_config}\")\n",
    "                            res = hyperparameter_tune(test_config)\n",
    "                            logging.info(f\"Results - (loss, mse, mae): {res}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42cc556-d833-4586-95fe-2409542405a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEST ACHIEVED RESULT \n",
    "BR_config = {'lr': 0.01, 'epochs': 30, 'batch_size': 1, 'lstm_units': 5, 'lookback': 10, 'output_activation': 'linear'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3813875-aa1a-4736-b4a3-29e990609af0",
   "metadata": {},
   "source": [
    "# Visualize best results for sale trend prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6019cc83-260a-42fe-8a5b-9c9b9b642ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data_trans = scaler.fit_transform(data_cleaned)\n",
    "\n",
    "train_size = int(len(data_trans) * 0.80)\n",
    "test_size = len(data_trans) - train_size\n",
    "train, test = data_trans[0:train_size,:], data_trans[train_size:len(data_trans),:]\n",
    "\n",
    "look_back = BR_config[\"lookback\"]\n",
    "train_data_gen = TimeseriesGenerator(train, \n",
    "                                     train,\n",
    "                                     length=look_back, \n",
    "                                     sampling_rate=1,\n",
    "                                     stride=1,\n",
    "                                     batch_size=BR_config[\"batch_size\"]\n",
    "                                    )\n",
    "test_data_gen = TimeseriesGenerator(test, \n",
    "                                    test,\n",
    "                                    length=look_back, \n",
    "                                    sampling_rate=1,\n",
    "                                    stride=1,\n",
    "                                    batch_size=BR_config[\"batch_size\"]\n",
    "                                   )\n",
    "\n",
    "x = Input(shape=(look_back, 1))\n",
    "h = LSTM(units=BR_config[\"lstm_units\"])(x) \n",
    "y = Dense(units=1, activation=BR_config[\"output_activation\"])(h)\n",
    "\n",
    "model = Model(inputs=x, outputs=y)\n",
    "print(model.summary())\n",
    "\n",
    "# compile model\n",
    "opt = Adam(learning_rate=BR_config['lr'])\n",
    "model.compile(loss='mean_squared_error', optimizer=opt, metrics=['mse', 'mae'])\n",
    "model.fit(train_data_gen, epochs=BR_config[\"epochs\"], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab81ede-3e69-4268-8dcb-77406f5d7f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_data_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b340d01-97e1-407f-be00-008a5903d88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPredict = model.predict(train_data_gen)\n",
    "print(trainPredict.shape)\n",
    "testPredict = model.predict(test_data_gen)\n",
    "print(testPredict.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343d11da-7a8c-46b4-85aa-a77087cdf69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "testPredict = scaler.inverse_transform(testPredict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66dffdd-c6dc-4365-87e5-438a308fbb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY = get_y_from_generator(train_data_gen)\n",
    "testY = get_y_from_generator(test_data_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f37c73-d0f8-4d61-a0fd-832464ef05c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY = scaler.inverse_transform(trainY)\n",
    "testY = scaler.inverse_transform(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdc886f-77e1-4caf-bfae-6defb9428b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainScore = math.sqrt(mean_squared_error(trainY[:,0], trainPredict[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testY[:, 0], testPredict[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fb3d51-6cdf-4b4a-954e-e6039b63a32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "begin =  look_back\n",
    "end = begin + len(trainPredict)\n",
    "\n",
    "trainYPlot = np.empty_like(data, dtype=float)  # Ensure dtype is float\n",
    "trainYPlot[:, :] = np.nan\n",
    "trainYPlot[begin:end, :] = trainY\n",
    "\n",
    "trainPredictPlot = np.empty_like(data, dtype=float)  # Ensure dtype is float\n",
    "trainPredictPlot[:, :] = np.nan\n",
    "trainPredictPlot[begin:end, :] = trainPredict\n",
    "\n",
    "trainTruePlot = np.empty_like(data, dtype=float)  # Ensure dtype is float\n",
    "trainTruePlot[:, :] = np.nan\n",
    "trainTruePlot[begin:end, :] = data[look_back:len(trainY)+look_back]\n",
    "\n",
    "# Plot baseline and predictions\n",
    "plt.figure(figsize=(24, 6))  # Adjusted figure size\n",
    "#plt.plot(data_org, label='Original Data')\n",
    "plt.plot(trainYPlot, label='Cleaned Values', color='blue')\n",
    "plt.plot(trainTruePlot, label='True Values', color='green')\n",
    "plt.plot(trainPredictPlot, label='Predicted Values', color='red')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffd8e69-26bb-4b8c-94c7-65a16186fd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "begin = train_size + look_back\n",
    "end = begin + len(testPredict)\n",
    "\n",
    "testYPlot = np.empty_like(data, dtype=float)  # Ensure dtype is float\n",
    "testYPlot[:, :] = np.nan\n",
    "testYPlot[begin:end, :] = testY\n",
    "\n",
    "testPredictPlot = np.empty_like(data, dtype=float)  # Ensure dtype is float\n",
    "testPredictPlot[:, :] = np.nan\n",
    "testPredictPlot[begin:end, :] = testPredict\n",
    "\n",
    "testTruePlot = np.empty_like(data, dtype=float)  # Ensure dtype is float\n",
    "testTruePlot[:, :] = np.nan\n",
    "testTruePlot[begin:end, :] = data[-len(testY):]\n",
    "\n",
    "# Plot baseline and predictions\n",
    "plt.figure(figsize=(24, 6))  # Adjusted figure size\n",
    "#plt.plot(data_org, label='Original Data')\n",
    "plt.plot(testYPlot, label='Cleaned Values', color='blue')\n",
    "plt.plot(testTruePlot, label='True Values', color='green')\n",
    "plt.plot(testPredictPlot, label='Predicted Values', color='red')\n",
    "\n",
    "\n",
    "plt.legend()  \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
