{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1714cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#    http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n",
    "# implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16237939",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning for Deep Learning Models (running cca 5min without GPU)\n",
    "\n",
    "The Keras Tuner is a library that helps you pick the optimal set of hyperparameters for your TensorFlow program. The process of selecting the right set of hyperparameters for your machine learning (ML) application is called hyperparameter tuning or hypertuning.\n",
    "\n",
    "URL: https://keras.io/guides/keras_tuner/getting_started/\n",
    "\n",
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dff262-dcde-4461-9845-2f70a97cba1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow keras-tuner -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa8afa8-512a-429e-84d3-8a1185ecb2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c5dc92-1ffe-459c-8ef5-d28e627f2af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1798eae3-3c34-4459-be9d-7b0aedda5441",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graphs(history):\n",
    "    plt.subplots(figsize=(15, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf0d078-7ed9-457a-bf74-4df33a99e023",
   "metadata": {},
   "source": [
    "### Load MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c049da-a1f9-4c7e-a954-088e39af63eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "(img_train, label_train), (img_test, label_test) = keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "# Normalize pixel values between 0 and 1\n",
    "img_train = img_train.astype('float32') / 255.0\n",
    "img_test = img_test.astype('float32') / 255.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607e6f85-9608-46db-a71b-d11e74a4d337",
   "metadata": {},
   "source": [
    "### Baseline Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac2ed8b-c826-4203-be20-8fe6f3915a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "\n",
    "def baseline_model(units, activation, dropout, lr):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(units=units, activation=activation))\n",
    "    if dropout:\n",
    "        model.add(layers.Dropout(rate=0.25))\n",
    "    model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78aa5253-ca2d-4e9f-b273-894b2940962c",
   "metadata": {},
   "source": [
    "### Define Hyperparameter Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf673749-e500-4973-b931-c009f696a720",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    units = hp.Int(\"units\", min_value=32, max_value=512, step=32)\n",
    "    activation = hp.Choice(\"activation\", [\"relu\", \"tanh\"])\n",
    "    dropout = hp.Boolean(\"dropout\")\n",
    "    lr = hp.Float(\"lr\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
    "    # call existing model-building code with the hyperparameter values.\n",
    "    model = baseline_model(\n",
    "        units=units, activation=activation, dropout=dropout, lr=lr\n",
    "    )\n",
    "    return model\n",
    "\n",
    "build_model(kt.HyperParameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f63f628-53dd-4c37-a8b9-92d7d12b58d6",
   "metadata": {},
   "source": [
    "### Instantiate the tuner and perform hypertuning\n",
    "\n",
    "The Keras Tuner currently supports four tuners:\n",
    "- `RandomSearch`\n",
    "- `Hyperband`\n",
    "- `BayesianOptimization`\n",
    "- `Sklearn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6aed6db-11bc-4d86-974b-b34e7383810f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tuner and parameters\n",
    "tuner = kt.Hyperband(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=10,\n",
    "    factor=3,\n",
    "    directory='my_dir',\n",
    "    project_name='intro_to_kt'\n",
    ")\n",
    "\n",
    "# Define callbacks\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55da0f7-5315-4494-8787-48159be0458d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Tuner\n",
    "tuner.search(img_train, label_train, epochs=10, validation_split=0.2, callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3becc8d-83fb-40be-a0ea-0777e8bf3de3",
   "metadata": {},
   "source": [
    "### Explore Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29813ae6-5a27-4647-8744-dfb5a9c469b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "pd.DataFrame([_.values for _ in tuner.get_best_hyperparameters(5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563b651a-e3df-41d5-ab54-309d5d796b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = tuner.get_best_models(num_models=2)\n",
    "best_model = models[0]\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b493da61-0992-46d4-8990-d3a0bc0b6924",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e0e7fa-f005-4ba3-b827-b91a419ed5d7",
   "metadata": {},
   "source": [
    "### Train the Model\n",
    "\n",
    "#### Find the optimal number of epochs to train the model with the hyperparameters obtained from search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f35f7d-7d3f-43f4-a844-4e7d2e7772f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tuner.hypermodel.build(best_hps)\n",
    "best_model_history = model.fit(img_train, label_train, epochs=10, validation_split=0.2)\n",
    "\n",
    "\n",
    "val_acc_per_epoch = best_model_history.history['val_accuracy']\n",
    "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "print(f'Best epoch: {best_epoch}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d47e39-0928-4cd9-83ae-0b5f9499a3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graphs(best_model_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d3df1d-bab2-41e3-85f8-b8be9c514463",
   "metadata": {},
   "source": [
    "#### Retrain the model with optimal number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e893c0-a4f6-441d-b231-667d8476b10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypermodel = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "# Retrain the model\n",
    "history = hypermodel.fit(img_train, label_train, epochs=best_epoch, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038abd40-f9b3-4ab5-a400-f2ebd94ce8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot graphs\n",
    "plot_graphs(best_model_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9357db4-eb37-4391-84dc-110ec9d61f0c",
   "metadata": {},
   "source": [
    "#### Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3971fda6-b041-455d-af8a-84e09c3dffe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_result = hypermodel.evaluate(img_test, label_test)\n",
    "print(f'[test loss, test accuracy]: {eval_result}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413ec6c7-e353-4db3-b07a-521e1344c58a",
   "metadata": {},
   "source": [
    "The `my_dir/intro_to_kt` directory contains detailed logs and checkpoints for every trial (model configuration) run during the hyperparameter search. If you re-run the hyperparameter search, the Keras Tuner uses the existing state from these logs to resume the search. To disable this behavior, pass an additional overwrite=True argument while instantiating the tuner."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
