{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fde477a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#    http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n",
    "# implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c36198a",
   "metadata": {},
   "source": [
    "# Understanding Bayesian Optimization\n",
    "\n",
    "[Bayesian optimization](https://arxiv.org/abs/1012.2599) is a powerful strategy for **finding the extrema of objective functions** that are expensive to evaluate. It is particularly useful when these evaluations are costly, when one does not have access to derivatives, or when the problem is non-convex.\n",
    "\n",
    "- **Objective function**\n",
    "\n",
    "- **Surrogate function**: Bayesian approximation of the objective function that can be sampled efficiently.\n",
    "\n",
    "- **Acquisition function**: Technique by which the posterior is used to select the next sample from the search space.\n",
    "\n",
    "The **Bayesian Optimization algorithm** can be summarized as follows.\n",
    "\n",
    "- 1. Select a sample by optimizing the Acquisition function.\n",
    "\n",
    "- 2. Evaluate the sample with the Objective function.\n",
    "\n",
    "- 3. Update data and, in turn, the Surrogate function.\n",
    "\n",
    "- 4. Go to 1.\n",
    "\n",
    "Based on URL: [Step-by-Step Guide to Bayesian Optimization: A Python-based Approach](https://medium.com/@okanyenigun/step-by-step-guide-to-bayesian-optimization-a-python-based-approach-3558985c6818)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec28404",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = (6, 4)\n",
    "np.random.seed(42)\n",
    "\n",
    "def plot_bbf(x, y, title):\n",
    "    plt.plot(x, y, color='black', linestyle='dotted', label='Black Box Function')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f233aad9",
   "metadata": {},
   "source": [
    "# 1. Black box function = Objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30f812f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def black_box_function(x):\n",
    "    y = np.sin(x) + np.cos(2*x)\n",
    "    return y\n",
    "\n",
    "# range of x values\n",
    "x_range = np.linspace(-2*np.pi, 2*np.pi, 100)\n",
    "\n",
    "# output for each x value\n",
    "black_box_output = black_box_function(x_range)\n",
    "\n",
    "# plot\n",
    "plot_bbf(x_range, black_box_output, 'Black Box Function Output')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a7ff19",
   "metadata": {},
   "source": [
    "# 2. Initial Sample - just a few expensive points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30b99f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random x values for sampling\n",
    "num_samples = 10\n",
    "sample_x = np.random.choice(x_range, size=num_samples)\n",
    "\n",
    "# output for each sampled x value\n",
    "sample_y = black_box_function(sample_x)\n",
    "\n",
    "# plot\n",
    "plot_bbf(x_range, black_box_function(x_range), 'Sampled Points')\n",
    "plt.scatter(sample_x, sample_y, color='red', label='Samples')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c85d762",
   "metadata": {},
   "source": [
    "# 3. Modeling a surrogate function by Gaussian Process with Initial Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c22336",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "\n",
    "# Gaussian process regressor with an RBF kernel\n",
    "kernel = RBF(length_scale=1.0)\n",
    "gp_model = GaussianProcessRegressor(kernel=kernel)\n",
    "\n",
    "# Fit the Gaussian process model to the sampled points\n",
    "gp_model.fit(sample_x.reshape(-1, 1), sample_y)\n",
    "\n",
    "# Generate predictions using the Gaussian process model\n",
    "y_pred, y_std = gp_model.predict(x_range.reshape(-1, 1), return_std=True)\n",
    "\n",
    "# Plot \n",
    "plot_bbf(x_range, black_box_function(x_range), 'Black Box Function with Gaussian Process Surrogate Model')\n",
    "plt.scatter(sample_x, sample_y, color='red', label='Samples')\n",
    "plt.plot(x_range, y_pred, color='blue', label='Gaussian Process')\n",
    "plt.fill_between(x_range, y_pred - 2*y_std, y_pred + 2*y_std, color='orange', alpha=0.2)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd1bde2",
   "metadata": {},
   "source": [
    "# 3. Acquisition Function\n",
    "Acquisition functions determine the next point or set of points to evaluate in the search space. \n",
    "\n",
    "### 3.1 Expected Improvement (EI) \n",
    "selects points that have the potential to improve upon the best-observed value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd628fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "def expected_improvement(x, gp_model, best_y):\n",
    "    y_pred, y_std = gp_model.predict(x.reshape(-1, 1), return_std=True)\n",
    "    z = (y_pred - best_y) / y_std\n",
    "    ei = (y_pred - best_y) * norm.cdf(z) + y_std * norm.pdf(z)\n",
    "    return ei\n",
    "\n",
    "# Determine the point with the highest observed function value\n",
    "best_idx = np.argmax(sample_y)\n",
    "best_x = sample_x[best_idx]\n",
    "best_y = sample_y[best_idx]\n",
    "\n",
    "ei = expected_improvement(x_range, gp_model, best_y)\n",
    "\n",
    "# Plot the expected improvement\n",
    "plt.plot(x_range, ei, color='green', label='Expected Improvement')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Expected Improvement')\n",
    "plt.title('Expected Improvement')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0138ad",
   "metadata": {},
   "source": [
    "### 3.2 Upper Confidence Bound (UCB) \n",
    "\n",
    "trades off exploration and exploitation by balancing the mean prediction of the surrogate model and an exploration term proportional to the uncertainty. It selects points that offer a good balance between predicted high values and exploration of uncertain regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfa0063",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upper_confidence_bound(x, gp_model, beta):\n",
    "    y_pred, y_std = gp_model.predict(x.reshape(-1, 1), return_std=True)\n",
    "    ucb = y_pred + beta * y_std\n",
    "    return ucb\n",
    "\n",
    "# Set the value of beta for the UCB acquisition function\n",
    "beta = 2.0\n",
    "\n",
    "# UCB\n",
    "ucb = upper_confidence_bound(x_range, gp_model, beta)\n",
    "\n",
    "# plot\n",
    "plt.plot(x_range, ucb, color='green', label='UCB')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('UCB')\n",
    "plt.title('UCB')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fdf3cc",
   "metadata": {},
   "source": [
    "### 3.3 Probability of Improvement (PI) \n",
    "estimates the probability that a point will improve upon the current best value. It considers the difference between the mean prediction and the current best value, taking into account the uncertainty in the surrogate model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235eec69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability_of_improvement(x, gp_model, best_y):\n",
    "    y_pred, y_std = gp_model.predict(x.reshape(-1, 1), return_std=True)\n",
    "    z = (y_pred - best_y) / y_std\n",
    "    pi = norm.cdf(z)\n",
    "    return pi\n",
    "\n",
    "# Probability of Improvement\n",
    "pi = probability_of_improvement(x_range, gp_model, best_y)\n",
    "\n",
    "# plot\n",
    "plt.plot(x_range, pi, color='green', label='PI')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('PI')\n",
    "plt.title('PI')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78588d60",
   "metadata": {},
   "source": [
    "# 4. Keep learning and improving - in every iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ad68e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iterations = 5\n",
    "\n",
    "for i in range(num_iterations):\n",
    "    # Fit the Gaussian process model to the sampled points\n",
    "    gp_model.fit(sample_x.reshape(-1, 1), sample_y)\n",
    "\n",
    "    # Determine the point with the highest observed function value\n",
    "    best_idx = np.argmax(sample_y)\n",
    "    best_x = sample_x[best_idx]\n",
    "    best_y = sample_y[best_idx]\n",
    "\n",
    "    # Set the value of beta for the UCB acquisition function\n",
    "    beta = 2.0\n",
    "\n",
    "    # Generate the Upper Confidence Bound (UCB) using the Gaussian process model\n",
    "    ucb = upper_confidence_bound(x_range, gp_model, beta)\n",
    "\n",
    "    # Plot the black box function, surrogate function, previous points, and new points\n",
    "    title = f\"Iteration #{i+1}\"\n",
    "    plot_bbf(x_range, black_box_function(x_range), title)\n",
    "    plt.plot(x_range, ucb, color='blue', label='Surrogate Function')\n",
    "    plt.scatter(sample_x, sample_y, color='red', label='Previous Points')\n",
    "    if i < num_iterations - 1:\n",
    "        new_x = x_range[np.argmax(ucb)]  # Select the next point based on UCB\n",
    "        new_y = black_box_function(new_x)\n",
    "        sample_x = np.append(sample_x, new_x)\n",
    "        sample_y = np.append(sample_y, new_y)\n",
    "        plt.scatter(new_x, new_y, color='green', label='New Points')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fc4285",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
